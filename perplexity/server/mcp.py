"""
MCP tools for Perplexity search.
Provides list_models, search, and research tools.
"""

import asyncio
from typing import Any, Dict, Iterable, List, Optional, Union

try:
    from ..config import LABS_MODELS, MODEL_MAPPINGS, SEARCH_MODES
except ImportError:
    from perplexity.config import LABS_MODELS, MODEL_MAPPINGS, SEARCH_MODES

try:
    from .app import mcp, run_query
except ImportError:
    from perplexity.server.app import mcp, run_query

# If mcp is None (e.g. testing env), create a dummy decorator
if mcp is None:
    class DummyMCP:
        def tool(self, func):
            return func
    mcp = DummyMCP()


def list_models_tool() -> Dict[str, Any]:
    """Return supported modes, model mappings, and Labs models."""
    return {
        "modes": SEARCH_MODES,
        "model_mappings": MODEL_MAPPINGS,
        "labs_models": LABS_MODELS,
    }


@mcp.tool
def list_models() -> Dict[str, Any]:
    """
    è·å– Perplexity æ”¯æŒçš„æ‰€æœ‰æœç´¢æ¨¡å¼å’Œæ¨¡å‹åˆ—è¡¨

    å½“ä½ éœ€è¦äº†è§£å¯ç”¨çš„æ¨¡å‹é€‰é¡¹æ—¶è°ƒç”¨æ­¤å·¥å…·ã€‚

    Returns:
        åŒ…å« modes (æœç´¢æ¨¡å¼)ã€model_mappings (æ¨¡å‹æ˜ å°„) å’Œ labs_models (å®éªŒæ¨¡å‹) çš„å­—å…¸
    """
    return list_models_tool()


@mcp.tool
async def search(
    query: str,
    mode: str = "pro",
    model: Optional[str] = None,
    sources: Optional[List[str]] = None,
    language: str = "en-US",
    incognito: bool = False,
    files: Optional[Union[Dict[str, Any], Iterable[str]]] = None,
    fallback_to_auto: bool = True,
) -> Dict[str, Any]:
    """
    Perplexity å¿«é€Ÿæœç´¢ - ç”¨äºè·å–å®æ—¶ç½‘ç»œä¿¡æ¯å’Œç®€å•é—®é¢˜è§£ç­”

    âš¡ ç‰¹ç‚¹: é€Ÿåº¦å¿«ï¼Œé€‚åˆéœ€è¦å®æ—¶ä¿¡æ¯çš„ç®€å•æŸ¥è¯¢

    Args:
        query: æœç´¢é—®é¢˜ (æ¸…æ™°ã€å…·ä½“çš„é—®é¢˜æ•ˆæœæ›´å¥½)
        mode: æœç´¢æ¨¡å¼
            - 'auto': å¿«é€Ÿæ¨¡å¼ï¼Œä½¿ç”¨ turbo æ¨¡å‹ï¼Œä¸æ¶ˆè€—é¢åº¦
            - 'pro': ä¸“ä¸šæ¨¡å¼ï¼Œæ›´å‡†ç¡®çš„ç»“æœ (é»˜è®¤)
        model: æŒ‡å®šæ¨¡å‹ (ä»… pro æ¨¡å¼ç”Ÿæ•ˆ)
            - None: ä½¿ç”¨é»˜è®¤æ¨¡å‹ (æ¨è)
            - 'sonar': Perplexity è‡ªç ”æ¨¡å‹
            - 'gpt-5.2': OpenAI æœ€æ–°æ¨¡å‹
            - 'claude-4.6-sonnet': Anthropic Claude
            - 'gemini-3.1-pro': Google Gemini Pro
            - 'grok-4.1': xAI Grok
        sources: æœç´¢æ¥æºåˆ—è¡¨
            - 'web': ç½‘é¡µæœç´¢ (é»˜è®¤)
            - 'scholar': å­¦æœ¯è®ºæ–‡
            - 'social': ç¤¾äº¤åª’ä½“
        language: å“åº”è¯­è¨€ä»£ç  (é»˜è®¤ 'en-US'ï¼Œä¸­æ–‡ç”¨ 'zh-CN')
        incognito: éšèº«æ¨¡å¼ï¼Œä¸ä¿å­˜æœç´¢å†å²
        files: ä¸Šä¼ æ–‡ä»¶ (ç”¨äºåˆ†ææ–‡æ¡£å†…å®¹)
        fallback_to_auto: å½“æ‰€æœ‰å®¢æˆ·ç«¯å¤±è´¥æ—¶ï¼Œæ˜¯å¦é™çº§åˆ°åŒ¿å auto æ¨¡å¼ (é»˜è®¤ True)

    Returns:
        {"status": "ok", "data": {"answer": "æœç´¢ç»“æœ...", "sources": [{"title": "...", "url": "..."}]}}
        æˆ– {"status": "error", "error_type": "...", "message": "..."}
    """
    # é™åˆ¶ search åªèƒ½ä½¿ç”¨ auto æˆ– pro æ¨¡å¼
    if mode not in ["auto", "pro"]:
        mode = "pro"
    # ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
    return await asyncio.to_thread(
        run_query, query, mode, model, sources, language, incognito, files, fallback_to_auto
    )


@mcp.tool
async def research(
    query: str,
    mode: str = "reasoning",
    model: Optional[str] = "gemini-3.1-pro",
    sources: Optional[List[str]] = None,
    language: str = "en-US",
    incognito: bool = False,
    files: Optional[Union[Dict[str, Any], Iterable[str]]] = None,
    fallback_to_auto: bool = True,
) -> Dict[str, Any]:
    """
    Perplexity æ·±åº¦ç ”ç©¶ - ç”¨äºå¤æ‚é—®é¢˜åˆ†æå’Œæ·±åº¦è°ƒç ”

    ğŸ§  ç‰¹ç‚¹: ä½¿ç”¨æ¨ç†æ¨¡å‹ï¼Œä¼šè¿›è¡Œå¤šæ­¥æ€è€ƒï¼Œç»“æœæ›´å…¨é¢å‡†ç¡®ï¼Œä½†è€—æ—¶è¾ƒé•¿

    Args:
        query: ç ”ç©¶é—®é¢˜ (é—®é¢˜è¶Šå…·ä½“ï¼Œç ”ç©¶ç»“æœè¶Šæœ‰é’ˆå¯¹æ€§)
        mode: ç ”ç©¶æ¨¡å¼
            - 'reasoning': æ¨ç†æ¨¡å¼ï¼Œå¤šæ­¥æ€è€ƒåˆ†æ (é»˜è®¤)
            - 'deep research': æ·±åº¦ç ”ç©¶ï¼Œæœ€å…¨é¢ä½†æœ€è€—æ—¶
        model: æŒ‡å®šæ¨ç†æ¨¡å‹ (ä»… reasoning æ¨¡å¼ç”Ÿæ•ˆ)
            - 'gemini-3.1-pro': Google Gemini Pro (é»˜è®¤ï¼Œæ¨è)
            - 'gpt-5.2-thinking': OpenAI æ€è€ƒæ¨¡å‹
            - 'claude-4.6-sonnet-thinking': Claude æ¨ç†æ¨¡å‹
            - 'kimi-k2-thinking': Moonshot Kimi
            - 'grok-4.1-reasoning': xAI Grok æ¨ç†
        sources: æœç´¢æ¥æºåˆ—è¡¨
            - 'web': ç½‘é¡µæœç´¢ (é»˜è®¤)
            - 'scholar': å­¦æœ¯è®ºæ–‡ (å­¦æœ¯ç ”ç©¶æ¨è)
            - 'social': ç¤¾äº¤åª’ä½“
        language: å“åº”è¯­è¨€ä»£ç  (é»˜è®¤ 'en-US'ï¼Œä¸­æ–‡ç”¨ 'zh-CN')
        incognito: éšèº«æ¨¡å¼ï¼Œä¸ä¿å­˜æœç´¢å†å²
        files: ä¸Šä¼ æ–‡ä»¶ (ç”¨äºåˆ†ææ–‡æ¡£å†…å®¹)
        fallback_to_auto: å½“æ‰€æœ‰å®¢æˆ·ç«¯å¤±è´¥æ—¶ï¼Œæ˜¯å¦é™çº§åˆ°åŒ¿å auto æ¨¡å¼ (é»˜è®¤ True)

    Returns:
        {"status": "ok", "data": {"answer": "ç ”ç©¶ç»“æœ...", "sources": [{"title": "...", "url": "..."}]}}
        æˆ– {"status": "error", "error_type": "...", "message": "..."}
    """
    # é™åˆ¶ research åªèƒ½ä½¿ç”¨ reasoning æˆ– deep research æ¨¡å¼
    if mode not in ["reasoning", "deep research"]:
        mode = "reasoning"
    # deep research æ¨¡å¼ä¸æ”¯æŒæŒ‡å®š model
    if mode == "deep research":
        model = None
    # ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
    return await asyncio.to_thread(
        run_query, query, mode, model, sources, language, incognito, files, fallback_to_auto
    )
